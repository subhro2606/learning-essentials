Elastic Block Store (EBS): 
Elastic Block Store (EBS) is a storage service that creates and manages volumes based on four underlying storage types. This is the network block storage product available within AWS. 
So that's storage presented over the network to EC2 instances.
Volumes are persistent, can be attached and removed from EC2 instances, and are replicated within a single AZ.
EBS Availability Zone Based Service:
•	EBS is an availability zone based service, and you can only attach volumes to instances which are both in the same availability zone.
•	EBS does replicate data inside the availability zones. 
•	So in this example, we've got availability zone A. We do have replication of the volume between different physical storage appliances but if the availability zone fails, you might very well lose the data on the EBS volume. 
•	Best case, it's going to be offline for a while the AZ is restored. 

*To protect against AZ failure, EBS snapshots (to 53) can be used. Data is replicated across AZs in the region and (optionally) internationally. 
Encryption:
Now you can encrypt a volume, and if you do, you'll need to pick an encryption key to use, which is provided by KMS or the key management service. When you create an encrypted EBS volume and attach it to a supported instance type, the following types of data are encrypted:
•	Data at rest inside the volume
•	All data moving between the volume and the instance
•	All snapshots created from the volume
•	All volumes created from those snapshots

Performance:
Storage performance is actually measured in two main ways. 
•	IOPS: IOPS is the number of input output operations the volume can cope within a given second. 
•	Throughput: Throughput is the data rate expressed in megabytes per second and this is based on the IOPS so the number of operations and then the block size of each operation. 
•	For example, a block size of 256 KB and then IOPS of 400 gives a 100 MiB/s throughput. 
Throughput = Block Size * IOPS
Dominant Performance Attribute:
Now each of the volume types has what's known as a dominant performance attribute. If it's IOPS then logically, the volume type focuses on high IOPS, and that is what both of the SSD based volumes do. 
•	For General Purpose SSD (gp2) & Provisioned IOPS SSD (io1) it is IOPS. 
•	For Throughput Optimized HDD (st1) & Cold HDD (sc1) is Throughput. 
If the dominant performance attributes is throughput, then you know that the IOPS will be suboptimal and the throughput will be the focus of the volume types. 
Volume Types:
•	Mechanical Hard disk drives (HDD): 
o	Throughput Optimized HDD (st1): Low cost, throughput intensive, can't be a boot volume
o	Cold HDD (sc1): Lowest cost, infrequent access, can't be boot volume
•	Solid-state drives (SSD): 
o	General Purpose SSD (gp2): Default, balance of IOPS/MiB/s - burst pool IOPS per GB
o	Provisioned IOPS SSD (io1): Highest performance, can adjust size and IOPS separately
Exam Facts and Figures: EBS 
• EBS supports a maximum per-instance throughput of 1,750 MiB/s and 80,000 IOPS. If you need more, you need to use instance store volumes. 
General Purpose SSD (gp2):
•	(SSD) Default for most workloads
•	3 IOPS per GiB (100 IOPS - 16,000 IOPS)
•	Bursts up to 3,000 IOPS (credit based)
•	1 GiB - 16 TiB size, max throughput p/vol of 250 MiB/s
•	gp2 volumes have two interesting characteristics. 
•	Use Cases:
o	General purpose SSD volume that balances price and performance for a wide variety of workloads.
o	Default Balance of IOPS(s) per GB
o	Recommended for most workloads
o	System boot volumes
o	Virtual desktops
o	Low-latency interactive apps
o	Development and test environments
Performance is linked to their size. With gp2 you actually get 3 IOPS of performance for every GB of volume size. It comes with a minimum level of 100 IOPS and a maximum of 16,000 IOPS. Now this is good and bad it means that you can control the performance of the volume based on the size but it does mean for smaller volumes you might hit performance ceilings. 
gp2 volumes come with what's known as a burst pool. With burst pool you get 5.4 million IO credits to start with. Any time you need IOPS above your baseline which remember, is based on the size of the volume you consume IOPS from your burst pool. Any time you're using less IOPS then your baseline, your pool replenishes. It helps give you some flexibility because even for smaller volumes, you've got this buffer that you can use to burst up to higher amounts. 
Even though the baseline performance is relatively low, remember though for the burst pool, the maximum is always 3000. 
So for the smaller volumes, you're always going to hit this 3000 IOPS ceiling. 
Now the maximum volume size for a gp2 volume is 16384 GB and size and note if I change it to that then my IOPS is 16,000. Once you go above one TB in size then the concept of this burst pool vanishes, and you always get the baseline performance. So for any volumes above one TB, you're always going to get a baseline IOPS performance of three times the size. 
Now gp2 is the default storage type because of this flexibility, if you don't have a reason to pick anything else then don't. 
Provisioned IOPS SSD (io1):
•	Used for applications that require sustained IOPS performance
•	Large database workloads
•	Volume size of 4 GiB - 16 TiB up to 64,000 IOPS per volume(Maximum ratio of 50:1 is permitted between IOPS and volume size.)
•	Max throughput p/vol of 1,000 MiB/s
•	Maximum ratio of 50:1 is permitted between IOPS and volume size.
•	Volumes with greater than 32000 IOPS must be attached to a Nitro based instance to achieve provisioned performance.
•	Use cases:
o	Highest-performance SSD volume for mission-critical low-latency or high-throughput workloads.
o	Can adjust size and IOPS separately
o	Critical business applications that require sustained IOPS performance, or more than 16,000 IOPS or 250 MiB/s of throughput per volume
o	Large database workloads, such as: MongoDB, Cassandra, Microsoft SQL Server, MySQL, PostgreSQL, Oracle

io1 is the final volume type available with EBS, and it's the most interesting it's known as provisioned IOPS. 
With io1, you can set an IOPS level on a volume size independently. Which means you're paying for the size of the volume, as well as paying for the performance that you set on it. 
Throughput Optimized HDD (st1):
•	Low storage cost
•	Used for frequently accessed, throughput-intensive workloads (streaming, big data)
•	Cannot be a boot volume
•	Volume size of 500 GiB - 16 TiB
•	Per-volume max throughput of 500 MiB/s and IOPS 500 
•	Use Case:
o	Low-cost HDD volume designed for frequently accessed, throughput-intensive workloads
o	Streaming workloads requiring consistent, fast throughput at a low price
o	Big data
o	Data warehouses
o	Log processing
o	Cannot be a boot volume

Cold HDD (sc1): (HDD)
•	Lowest cost
•	Infrequently accessed data
•	Cannot be a boot volume
•	Volume size of 500 GiB - 16 TiB
•	Use Case:
o	Per-volume max throughput of 250 MiB/s and 250 IOPS 
o	Lowest cost HDD volume designed for less frequently accessed workloads
o	Throughput-oriented storage for large volumes of data that is infrequently accessed
o	Scenarios where the lowest storage cost is important
o	Cannot be a boot volume

Exam Tips:
**The first is that there is a maximum performance available on any one single EBS volume of 64,000 IOPS and that's only available on the largest high performance instances that are based on Nitro. 
Anything else generally tops out at 32,000. Instances themselves have a maxim IOPS of 80,000 when using EBS. 
So keep those figures in mind 64,000 for a volume and 80,000 for the instance. 
If you want anything above that, then you need to use instance store volumes and remember, they're not persistent. So if the instance moves between hosts or you stop and start it for any other reason or there's a hardware failure, you can lose the data. 
So you might face exam questions where you need to determine what type of volume to use. 
These key values will help you understand that anything above 80,000 and it needs to be instance store volume and then for that, you need to make sure that there is not any limitation on the fact that you can't afford data loss. 
Most modern instance types support what are known as elastic volume, so you're able to change the volume type and the size without causing instance downtime but if you're using an older instance, type which doesn't support elastic volumes, you will need to shut down the instance to make this change. 
You can create volumes attached them to instances, but remember, the volumes are in a particular availability zone, and if you want to move them between availability zones or regions you need to use snapshots


############################################################################################################################################
Welcome back. 
This is part two of this video we're going to carry on immediately from the end of part one. 
So let's get started. 
So next I want to talk about EBS or elastic block store, which is the network block storage product available within AWS. 
So that's storage presented over the network to EC2 instances. 
To access that I could go to elastic block store and volumes and this is the same service that you use when you create an instance and includes that default root volume. 
Doing it this way is exactly the same as creating these volumes from inside the instance. 
So I'll click Create Volume. Now you have lots of options available when creating volumes. 
I want to quickly step through the important ones. 
The first thing is, you need to pick a type of volume and that really controls what technology is used to provide it. 
Does it use mechanical or magnetic hard disks or newer, solid state technology and I'll talk more about these in a second. 

You also need to pick a particular availability zone for that volume to occupy. 


Availablity Zone Based Service:
**EBS is an availability zone based service, and you can only attach volumes to instances which are both in the same availability zone.
So keep this in mind if you create volumes after you've created an instance, make sure you're creating the volume in the same availability zone as the instance that you're going to attach it to. 
EBS does replicate data inside the availability zones. 
So in this example, we've got availability zone A. 
We do have replication of the volume between different physical storage appliances but if the availability zone fails, you might very well lose the data on the EBS volume. 
Best case, it's going to be offline for a while while the AZ is restored. 

Now volumes could be created either as a blank volume or based on an EBS snapshot. 

We haven't talked about EBS snapshots yet. 
I'll be covering those in the next lesson but for now, think of snapshots as a backup of a volume, so creating a new volume from a snapshot ID is equivalent to restoring a backup. 

Encryption:
Now you can encrypt a volume, and if you do, you'll need to pick an encryption key to use, which is provided by KMS or the key management service but more on that later in the course, EBS encryption just ensures that any data that's stored on physical drives is always encrypted at rest and ensures that data is encrypted moving between the volume and the instance. 

Now, I've got a dedicated lesson coming up in the EC2 advanced topic where I talk about volume encryption. 
So I'm not going to dwell on this now, I just want you to be aware that the capability exists. 
So I want to talk quickly about the different volume types available in EBS. 
So we've got four main types. 
We got gp2 and io1 which are based on solid state discs and then we've got sc1 and st1, which are both based on hard disk drives. 
So these are mechanical or magnetic drives. 
There is a legacy standard which is magnetic standard, but this tends not to be used anymore. 
It's highly recommended that you either use the hard disk based volume types or the solid state volume types don't use this magnetic standard it doesn't really offer any benefits of either cost or performance. 
Now, each of these four types of storage uses a different underlying technology to support it. 

Performance:
Storage performance is actually measured in two main ways. 
We've got IOPS, which is the number of input output operations the volume can cope within a given second. 
Then we've got a throughput, which is the data rate expressed in megabytes per second and this is based on the IOPS so the number of operations and then the block size of each operation. 
So, for example, a block size of 256 KB and then IOPS of 400 gives a 100 meg per second throughput. 
Both of those are related. 
To get the throughput, you always multiply the block size by the IOPS. 
Now each of the volume types has what's known as a dominant performance attribute. 
If it's IOPS then logically, the volume type focuses on high IOPS, and that is what both of the SSD based volumes do. 
So both of these, their dominant performance attribute is IOPS. 
If the dominant performance attributes is throughput, then you know that the IOPS will be suboptimal and the throughput will be the focus of the volume types. 
So keep that in mind. 

When you're looking at the different volume types at a high level, you want to be picking the one that suits your workload. 
Either it's a throughput demanding workload, or it's an IOPS demanding workload and based on that, you already can eliminate two of these volume types. 
So at a really high level, we've got sc1 and st1 and these are mechanical or magnetic disks. 
We've got gp2 and io1, which are SSD or solid state disks. 

If you're only going to remember four key facts regarding volume types from this lesson, it's the sc1 is a mechanical storage type. 
It's designed for lowest cost, infrequent access, and it can't be a boot volume. 
st1 low cost, throughput intensive, and it also can't be a boot volume. 
gp2 this is the default volume type. 
It's a great balance of IO operations per second and throughput, and it includes a burst pool of a certain number IOPS and don't worry, we'll talk about that in a second. 
io1 is the highest performance, and you can adjust the size and the IOPS separately. 

So let's look in a little bit more detail at the different types of volumes and their characteristics. 
Now, before this concerns you, you do not have to remember all of these facts for the exam. 
I just wanted to provide you with the data so that you can refer to this as you go through the course. 
So let's start with st1. 
st1 volumes are designed for low cost and they're optimized for throughput. 
In other words, the amount of data they can store or retrieve in a given period. 
Now with st1, there's no penalty or benefit for data access patterns, so it's not really something that's beneficial for archival. 
It's a pretty standard mechanical storage type. 
It's best suited for workloads, such a streaming video, big data workloads, or anything where large data sets are read or written sequentially. 
st1 is great for log processing or other time series data again, where data is used sequentially. 
But keep in mind for the exam, that st1 volumes cannot be used for boot volumes. 
You might get that question where you're asked to pick a suitable volume type and that is often the thing that distinguishes between two different answers. 
Now I want to draw attention specifically to the IOPS not applicable. 
This is not an IOPS based volume. 
So if you look at the detailed stats, you are generally going to get a max IOPS 500. 
You're not going to be picking this volume type if you're concerned in any way about IOPS. 
Likewise, we've got the cold HDD or sc1. 
Now, this is the lowest cost storage available within EBS. 
It's designed for data which is less frequently accessed. 
So it makes excellent archival storage, maybe a warm tier where you need to still access the data at times, but do so infrequently. 
Now just as with sc1, you cannot use this as a boot volume, so it limits its usage to very niche situational use cases. 

If you've got any exam questions where you need to use boot volumes, keep in mind that neither of the mechanical or magnetic volume types can be used as boot volumes and both of these that's sc1 and st1. 
You're generally only going to select them in very specific cases. 
Now we've got gp2 and gp2 is a solid state volume type, so it uses SSD drives is also the default and for good reason. 
Rather than using physically moving parts, it uses a type of memory which can keep its data secure when there's no power. 
The benefit of solid state volumes is that they're generally really fast in terms of their throughput and exceptionally fast in terms of the number of IOPS that they can handle. 
gp2 volumes have two interesting characteristics. 
The first is that their performance is linked to their size. 
So note that in this case, the IOPS that this volume can generate, you've got a base level of 1500 a maximum of 3000. 
Watch what happens if I change this 500 to 750. 
When I do that, the base level IOPS moves to 2250 and the maximum stays as 3000 with gp2 you actually get three IOPS of performance for every GB of volume size. 
It comes with a minimum level of 100 IOPS and a maximum of 16,000 IOPS. 
Now this is good and bad it means that you can control the performance of the volume based on the size but it does mean for smaller volumes you might hit performance ceilings. 
The second characteristic actually mitigates this a little bit. 
gp2 volumes come with what's known as a burst pool. 
With burst pool you get 5.4 million IO credits to start with. 
Any time you need IOPS above your baseline which remember, is based on the size of the volume you consume IOPS from your burst pool. 
Any time you're using less IOPS then your baseline, your pool replenishes. 
It helps give you some flexibility because even for smaller volumes, you've got this buffer that you can use to burst up to higher amounts. 
Even though the baseline performance is relatively low, remember though for the burst pool, the maximum is always 3000. 
So for the smaller volumes, you're always going to hit this 3000 IOPS ceiling. 
Now the maximum volume size for a gp2 volume is 16384 GB and size and note if I change it to that then my IOPS is 16,000. 
Once you go above one TB in size then the concept of this burst pool vanishes, and you always get the baseline performance. 
So for any volumes above one TB, you're always going to get a baseline IOPS performance of three times the size. 
Now gp2 is the default storage type because of this flexibility, if you don't have a reason to pick anything else then don't. 





io1 is the final volume type available with EBS, and it's the most interesting it's known as provisioned IOPS. 
With io1, you can set an IOPS level on a volume size independently. 
So note how I can change the volume size as well as the IOPS with the io1 volume type only you're paying for the size of the volume, but you're also paying for the performance that you set on it. 
Now, there is one really important thing that I want to draw your attention to, and that is that there are some maximums that you need to be aware of the exam. 
So you won't need to memorize all of these details but there are a number of key values that I will want you to remember. 


The first is that there is a maximum performance available on any one single EBS volume of 64,000 IOPS and that's only available on the largest high performance instances that are based on Nitro. 
Anything else generally tops out at 32,000. 
Instances themselves have a maxim IOPS of 80,000 when using EBS. 
So keep those figures in mind 64,000 for a volume and 80,000 for the instance. 
If you want anything above that, then you need to use instance store volumes and remember, they're not persistent. 
So if the instance moves between hosts or you stop and start it for any other reason or there's a hardware failure, you can lose the data. 
So you might face exam questions where you need to determine what type of volume to use. 
These key values will help you understand that anything above 80,000 and it needs to be instance store volume and then for that, you need to make sure that there is not any limitation on the fact that you can't afford data loss. 
Keep that in mind, it's really important you will get exam questions relating to the storage selection. 
Now you can change the volume size of an EBS volume. 
So if you right click on the volume, modify the volume, you're able to change the volume type as well as the size. 
Most modern instance types support what are known as elastic volume, so you're able to change the volume type and the size without causing instance downtime but if you're using an older instance, type which doesn't support elastic volumes, you will need to shut down the instance to make this change. 
Now, using EBS volumes is easy. 
You just need to create the volume and attach it to the EC2 instance, remember because EBS volumes are availability zone based. 
You'll need to verify which availability zone an instance is in. 
In this case, an example instance that I've got up and running is in the U.S. 
East 1a. 
So I'll have to create the volume also in U.S. 
East 1a. 
So I click on Create Volume. Make sure U.S. 
East 1a is selected, pick the volume type that I want to use gp2 is the default, so I'll go with that. 
I'll set it to a size so it can identify it and for gp2 the minimum size is 1 GB and the maximum is 16384 Do be aware that these sizes do differ. 
So for io1, the minimum size is 4 GB and the maxim is 16384. 
If you consult The Orion Papers, I do give you an indication of the minimum and maximum values for the different types of volume. 
You won't need to know that for the exam, but I do recommend trying to memorize even at a high level the minimum and maximum performance characteristics of each type. 
In this case, I'm going to create a gp2 volume. 
I'm going to set it to 111 GB so I could identify it. 
I'm not going to select a snapshot ID because I want to create this volume as a blank volume, and I'll create the volume. 
After a few moments, the volume gets created and it's in an available state and when it's in that state, it means I can right click, attach the volume, and pick an instance to attach the volume to and it'll list any instances that are in the same availability zone as this volume. 
In this case, I've only got the one instance. 
So I select it. 
I'll be prompted for a device. 
Remember the block device mapping so every time you map an EBS volume or an instance store volume to an instance, you need to pick the device that will get mapped to that instance with. 
Now, there are some operating system intricacies you need to be aware of. 
So depending on the operating system that use, you might have to use a certain format for this device mapping. 
In this case, I'm just going to go ahead and leave it as default and hit Attach and at this point, it will be attached to the instance you'll be able to connect into the guest operating system and attach it as a mount point using whatever process is applicable for that operating system. 
Now, for any volumes are attached to instances, you're able to detach that volume from that instance so you can attach it to another instance if you want. 
If you have any problems detaching the volume, maybe any locks or any in use issues, you can force detach the volume but I wouldn't recommend doing that unless you have to, and you're also able to change the auto enable IO setting. 
If AWS detect any data consistency issues with the volume, it'll automatically suspend any input output to and from that volume. 
If it's a volume, where you're not overly concerned with the consistency of the data or it's something you can easily recreate. 
Then you can check this to automatically reenable IO on the volume. 
Even though consistency errors have been detected. 
Now, I don't recommend using this in almost any situation. 
If you do have any situations where you've got data consistency issues on a volume, you'll want to conduct an investigation and reenable it manually after that investigation so volumes could be created in a specific availability zone. 
They could be attached to incidences in that availability zone. 
They could be detached from those instances, reattached to other instances, and moved as an independent entity. 
That's the critical part to understand about EBS. 
Whilst root volumes do get created with instances, EBS is a separate product. 
You can create individual volumes and attach those to individual instances. 
You can remove them, you can move them, and when you do so the data that's stored on those volumes is moved between the instances. 
So EBS volumes a persistent and reliable data stores, and you can use them to achieve really good performance. 
Now that's everything I wanted to cover in this lesson. 
It has been a lot of theory, I know, but it's really important for you to understand the difference between EBS and instance store with instance store using physical devices that are on the EC2 hosts. 
If for any reason the device fails or you move hosts, you'll lose that data but it offers performance that is much higher than the 80,000 that you can get from EBS. 
With certain types of instance store volumes on certain type of instances, such as the I3en. 
You're able to get over two million IOPS so keep in mind instance store volumes deliver much higher performance, but EBS is what you need to use if you need reliability. 
EBS is a network storage based product. 
You can create volumes attached them to instances, but remember, the volumes are in a particular availability zone, and if you want to move them between availability zones or regions you need to use snapshots and that's what we're going to be covering next. 
So go ahead, mark this video as complete and when you're ready, join me in the next.